{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TTLT_Exercise_Intermediate.ipynb","provenance":[],"collapsed_sections":["U6iAHx5M8bKe","-PDwslA_9OHA","LuMFlpnk-PI9","bPCA-oXl-9HW","WZ_EcY37_v39","mZ35u5obBHMU","HpLZKyKgB49I","ORyGBYarCRy5","TyBT5gRjDMxw","a4ROngg1DjK3"],"authorship_tag":"ABX9TyMkfPlLg2msd4m4yPwGUmKq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"LmTRIfgW42c7"},"source":["# A primer on artificial intelligence in plant digital phenomics: embarking on the data to insights journey (*Tutorial*)"]},{"cell_type":"markdown","metadata":{"id":"XrceqdN94lkt"},"source":["This notebook is a supplement to the paper **A primer on artificial intelligence in plant digital phenomics: embarking on the data to insights journey** (submitted to *Trends in Plant Science, 2022*) by Antoine L. Harfouche, Farid Nakhle, Antoine H.\n","Harfouche, Orlando G. Sardella, Eli Dart, and Daniel Jacobson.\n","\n","Read the accompanying paper [here](https://doi.org) (a link will be available once the paper is published)."]},{"cell_type":"markdown","metadata":{"id":"cOQ9Xxkf40AM"},"source":["Before attempting to solve the exercises found in this notebook, visit our Github repository and try to open and run the notebook provided by the tutorial. \n","\n","Here, the solution for each exercise can be found in a hidden code cell at its end.\n","\n","Interested users should try to solve the exercises with the help of the notebook provided by the tutorial before looking at the solution."]},{"cell_type":"markdown","metadata":{"id":"6vtVIEPE48DH"},"source":["**It is important to note that Colab deletes all unsaved data once the instance is recycled. Therefore, remember to download your results once you run the code.**"]},{"cell_type":"markdown","metadata":{"id":"TaYNvHN37-GO"},"source":["#Exercise I: dataset preparation"]},{"cell_type":"markdown","metadata":{"id":"igjrPSO68HY9"},"source":["The next code block defines a function that downloads files from Google Drive based on the file ID. \n","\n","Use this function to download the cassava dataset hosted on Google Drive at https://drive.google.com/file/d/13jwC684Sg1wWLhF7SjPIlsfJNuKqJ_IQ/view?usp=sharing."]},{"cell_type":"code","metadata":{"id":"RSUhmoKj8BDc"},"source":["import requests\n","\n","def download_file_from_google_drive(id, destination):\n","    URL = \"https://docs.google.com/uc?export=download\"\n","\n","    session = requests.Session()\n","\n","    response = session.get(URL, params = { 'id' : id }, stream = True)\n","    token = get_confirm_token(response)\n","\n","    if token:\n","        params = { 'id' : id, 'confirm' : token }\n","        response = session.get(URL, params = params, stream = True)\n","\n","    save_response_content(response, destination)    \n","\n","def get_confirm_token(response):\n","    for key, value in response.cookies.items():\n","        if key.startswith('download_warning'):\n","            return value\n","\n","    return None\n","\n","def save_response_content(response, destination):\n","    CHUNK_SIZE = 32768\n","\n","    with open(destination, \"wb\") as f:\n","        for chunk in response.iter_content(CHUNK_SIZE):\n","            if chunk: # filter out keep-alive new chunks\n","                f.write(chunk)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kddEfyi18rw5"},"source":["### WRITE YOUR CODE HERE ###"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U6iAHx5M8bKe"},"source":["#Solution"]},{"cell_type":"code","metadata":{"id":"vhQLvy8a4Rli"},"source":["file_id = '13jwC684Sg1wWLhF7SjPIlsfJNuKqJ_IQ'\n","destination = '/content/dataset.zip'\n","download_file_from_google_drive(file_id, destination)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NzryC1Fj85KG"},"source":["# Exercise II: data extraction"]},{"cell_type":"markdown","metadata":{"id":"jUtgOUQJ9DGO"},"source":["Complete the code using the unzip command to extract the dataset to /content/dataset"]},{"cell_type":"code","metadata":{"id":"G8rhEWqD9K8h"},"source":["!mkdir /content/dataset\n","!apt-get install unzip\n","### Write YOUR CODE HERE ###"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-PDwslA_9OHA"},"source":["#Solution"]},{"cell_type":"code","metadata":{"id":"YS2l7bHa9Suq"},"source":["#unzip dataset\n","!mkdir /content/dataset\n","!apt-get install unzip\n","!unzip /content/dataset.zip -d /content/dataset/\n","!rm -R  /content/dataset.zip #save some space"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hj5cb0LJ9bbp"},"source":["#Exercise III: descriptive data analysis"]},{"cell_type":"markdown","metadata":{"id":"ocsaesac94Bv"},"source":["The next code block will count all images in every class in the training dataset and bar plot will be used to display the results. This helps us discover whether or not our training dataset is balanced over all classes."]},{"cell_type":"code","metadata":{"id":"GA8vgEQG93lX"},"source":["import numpy as np\n","import pandas as pd\n","import os\n","import shutil\n","import cv2\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","train_dir = '/content/dataset/cdsv5/train/'\n","train_classes = [path for path in os.listdir(train_dir)]\n","train_imgs = dict([(ID, os.listdir(os.path.join(train_dir, ID))) for ID in train_classes])\n","train_classes_count = []\n","for trainClass in train_classes:\n","  train_classes_count.append(len(train_imgs[trainClass]))\n","\n","plt.figure(figsize=(15, 10))\n","g = sns.barplot(x=train_classes, y=train_classes_count)\n","g.set_xticklabels(labels=train_classes, rotation=30, ha='right')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kljflJAG-Iir"},"source":["Use the code above to check the distribution of the augmented training dataset located under /content/dataset/cdsv5/train_aug"]},{"cell_type":"code","metadata":{"id":"3U1AAtdh-QJs"},"source":["### WRITE YOUR CODE HERE ###"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LuMFlpnk-PI9"},"source":["#Solution"]},{"cell_type":"code","metadata":{"id":"fHVnQZ7W-YJG"},"source":["train_dir = '/content/dataset/cdsv5/train_aug/'\n","train_classes = [path for path in os.listdir(train_dir)]\n","train_imgs = dict([(ID, os.listdir(os.path.join(train_dir, ID))) for ID in train_classes])\n","train_classes_count = []\n","for trainClass in train_classes:\n","  train_classes_count.append(len(train_imgs[trainClass]))\n","\n","plt.figure(figsize=(15, 10))\n","g = sns.barplot(x=train_classes, y=train_classes_count)\n","g.set_xticklabels(labels=train_classes, rotation=30, ha='right')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DSeQtm2u-oF_"},"source":["#Exercise IV: cloning a GitHub repository"]},{"cell_type":"markdown","metadata":{"id":"HoKnoE4T-s3y"},"source":["Our implementation of the 'this looks like that' interpretable by design AI algorithm is hosted on our GitHub repository at https://github.com/HarfoucheLab/A-Primer-on-AI-in-Plant-Digital-Phenomics. \n","\n","Clone this repository under /content to obtain the code so that you can use it later on to train a model."]},{"cell_type":"code","metadata":{"id":"QgtodbAa-9Wc"},"source":["### YOUR CODE HERE ###"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bPCA-oXl-9HW"},"source":["#Solution"]},{"cell_type":"code","metadata":{"id":"pcORqc_I_AMR"},"source":["!git clone https://github.com/HarfoucheLab/A-Primer-on-AI-in-Plant-Digital-Phenomics.git"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7xxhp583_E-U"},"source":["#Exercise V: configuring 'this looks like that'"]},{"cell_type":"markdown","metadata":{"id":"84eoXwWi_Iwa"},"source":["As in any AI algorithm, 'this looks like that' requires some hyperparameters to be set before running it. To satisfy these requirements, we save all hyperparameters in a file called settings.py located under /content/A-Primer-on-AI-in-Plant-Digital-Phenomics/settings.py.\n","\n","The settings are defined in a string variable in the next code block.\n","\n","Complete the code that saves these settings to settings.py."]},{"cell_type":"code","metadata":{"id":"i4_-GbHx_hFi"},"source":["settings = \"\"\"base_architecture = 'densenet161'\n","img_size = 224\n","prototype_shape = (2000, 128, 1, 1)\n","num_classes = 5\n","prototype_activation_function = 'log'\n","add_on_layers_type = 'regular'\n","\n","experiment_run = '001'\n","\n","data_path = '/content/dataset/cdsv5/'\n","train_dir = data_path + 'train_aug/'\n","test_dir = data_path + 'val/'\n","train_push_dir = data_path + 'train/'\n","train_batch_size = 40 #80\n","test_batch_size = 40\n","train_push_batch_size = 64\n","\n","num_workers=3\n","min_saving_accuracy=0.05\n","\n","joint_optimizer_lrs = {'features': 1e-4,\n","                       'add_on_layers': 3e-3,\n","                       'prototype_vectors': 3e-3}\n","joint_lr_step_size = 5\n","\n","warm_optimizer_lrs = {'add_on_layers': 3e-3,\n","                      'prototype_vectors': 3e-3}\n","\n","last_layer_optimizer_lr = 1e-4\n","\n","coefs = {\n","    'crs_ent': 1,\n","    'clst': 0.8,\n","    'sep': -0.08,\n","    'l1': 1e-4,\n","}\n","\n","num_train_epochs = 1000\n","num_warm_epochs = 5\n","\n","push_start = 10\n","push_epochs = [i for i in range(num_train_epochs) if i % 10 == 0] \"\"\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"y1zkkykg_roH"},"source":["text_file = open(\"/content/A-Primer-on-AI-in-Plant-Digital-Phenomics/py/settings.py\", \"w\")\n","### YOUR CODE HERE ###\n","text_file.close()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WZ_EcY37_v39"},"source":["#Solution"]},{"cell_type":"code","metadata":{"id":"VJe5XbCQ_w1r"},"source":["text_file = open(\"/content/A-Primer-on-AI-in-Plant-Digital-Phenomics/py/settings.py\", \"w\")\n","n = text_file.write(settings)\n","text_file.close()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U3DI7Yf8Axzu"},"source":["#Exercise VI: training 'this looks like that'"]},{"cell_type":"markdown","source":[""],"metadata":{"id":"T4hh8CL73Exd"}},{"cell_type":"markdown","metadata":{"id":"VOcjZc1pA1xi"},"source":["Now with the settings all set, run the code located in mainDistributed.py under /content/A-Primer-on-AI-in-Plant-Digital-Phenomics/py to start the training process.\n","\n","Hint: use 1 node, 1 gpu, and set nr to 0."]},{"cell_type":"code","metadata":{"id":"7Imu4CVvA0ck"},"source":["%cd /content/A-Primer-on-AI-in-Plant-Digital-Phenomics/py/\n","### WRITE YOUR CODE HERE ###"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mZ35u5obBHMU"},"source":["#Solution"]},{"cell_type":"code","metadata":{"id":"so4ISLMzA-PW"},"source":["%cd /content/A-Primer-on-AI-in-Plant-Digital-Phenomics/py/\n","!python3 mainDistributed.py --nodes 1 --gpus 1 --nr 0"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9GjNMBqKBOBi"},"source":["#Exercise VII: using a pretrained model"]},{"cell_type":"markdown","metadata":{"id":"9czbDy6oBQWW"},"source":["The next codeblock will download a pretrained model which will be extracted to /content/pretrained and a testing dataset which will be extracted to /content/dataset/cdsv5/test. "]},{"cell_type":"code","metadata":{"id":"8dOFUKILBP7p"},"source":["%cd /content/\n","file_id = '12ugCaMfPdylDPPmfqzoOMWtB55k0L9tL'\n","destination = '/content/pretrained.zip'\n","download_file_from_google_drive(file_id, destination)\n","mkdir /content/pretrained\n","!unzip /content/pretrained.zip -d /content/pretrained/\n","!rm -R /content/pretrained.zip\n","file_id = '1Ruy2At0G3oLlA1Gb9gz1-aMpcfJ6653B'\n","destination = '/content/dataset_test.zip'\n","download_file_from_google_drive(file_id, destination)\n","!unzip /content/dataset_test.zip -d /content/dataset/cdsv5/\n","!rm -R /content/dataset_test.zip"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"78NMR3DKBi3l"},"source":["Complete the code below to use the downloaded pretrained model and test dataset to test the model performance and generate the confusion matrix. \n","\n","Hint: The python file for the the testing and confusion matrix generation is located under /content/A-Primer-on-AI-in-Plant-Digital-Phenomics/py/RunTestAndConfusionMatrix.py"]},{"cell_type":"code","metadata":{"id":"7ea2DAwwBsxU"},"source":["%cd /content/A-Primer-on-AI-in-Plant-Digital-Phenomics/py/\n","### YOUR CODE HERE ###"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HpLZKyKgB49I"},"source":["#Solution"]},{"cell_type":"code","metadata":{"id":"34pGjXN4B6Vj"},"source":["%cd /content/A-Primer-on-AI-in-Plant-Digital-Phenomics/py/\n","!python3 RunTestAndConfusionMatrix.py\n","%cd /content/"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uTTN-uU9B811"},"source":["#Exercise VIII: generating the confusion matrix"]},{"cell_type":"markdown","metadata":{"id":"iqRLO2rxCDkK"},"source":["Testing the pretrained model should have generated a PNG file containing the confusion matrix located under /content/confusion_matrix.png.\n","\n","Complete the below code to display the confusion matrix."]},{"cell_type":"code","metadata":{"id":"3KgxML6wB_Sa"},"source":["import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","\n","img = mpimg.imread('/content/confusion_matrix.png')\n","### YOUR CODE HERE ###\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ORyGBYarCRy5"},"source":["#Solution"]},{"cell_type":"code","metadata":{"id":"rvdJj1uZCS5e"},"source":["import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","\n","img = mpimg.imread('/content/confusion_matrix.png')\n","plt.figure(figsize=(10,10))\n","plt.imshow(img)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_nCADrPuCYDP"},"source":["# Exercise IX: explaning predictions"]},{"cell_type":"markdown","metadata":{"id":"GNpNTaCrCbZ6"},"source":["Explanations to predictions are generated by running a local analysis on a specific image. To do so, the local_analysis.py python file located under /content/A-Primer-on-AI-in-Plant-Digital-Phenomics/py is used.\n"]},{"cell_type":"code","metadata":{"id":"UbThzOEaCq3S"},"source":["!python3 /content/A-Primer-on-AI-in-Plant-Digital-Phenomics/py/local_analysis.py -modeldir /content/pretrained/ -model 240_12push0.8884.pth -imgdir /content/dataset/cdsv5/test/1/ -img 931787054.jpg -imgclass 1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HsZqri0FCuVb"},"source":["Running the above codeblock should have generated many images under /content/dataset/cdsv5/test/1/pretrained/240_12push0.8884.pth/top-1_class_prototypes. \n","\n","Complete the python code below to display the best explanation generated for the prediction of the test image located under /content/dataset/cdsv5/test/1/931787054.jpg"]},{"cell_type":"code","metadata":{"id":"lUgObGgsDFeT"},"source":["img = mpimg.imread('/content/dataset/cdsv5/test/1/pretrained/240_12push0.8884.pth/top-1_class_prototypes/prototype_activation_map_by_top-1_prototype.png')\n","### WRITE YOUR CODE HERE ###"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TyBT5gRjDMxw"},"source":["#Solution"]},{"cell_type":"code","metadata":{"id":"Zj5S99mkDMS1"},"source":["img = mpimg.imread('/content/dataset/cdsv5/test/1/pretrained/240_12push0.8884.pth/top-1_class_prototypes/prototype_activation_map_by_top-1_prototype.png')\n","plt.figure(figsize=(10,10))\n","plt.imshow(img)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"l3Gi7EaSDMEQ"},"source":["#Exercise X: displaying the prototypes"]},{"cell_type":"markdown","metadata":{"id":"zzqX3uK8DP-I"},"source":["Complete the next codeblock to display the best two prototypes used for the classification on the above explained image."]},{"cell_type":"code","metadata":{"id":"INsIqmKFDZrQ"},"source":["img = mpimg.imread('/content/dataset/cdsv5/test/1/pretrained/240_12push0.8884.pth/top-1_class_prototypes/top-1_activated_prototype.png')\n","img2 = mpimg.imread('/content/dataset/cdsv5/test/1/pretrained/240_12push0.8884.pth/top-1_class_prototypes/top-2_activated_prototype.png')\n","### WRITE YOUR CODE HERE ###"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a4ROngg1DjK3"},"source":["#Solution"]},{"cell_type":"code","metadata":{"id":"KR3arYTTDgGM"},"source":["img = mpimg.imread('/content/dataset/cdsv5/test/1/pretrained/240_12push0.8884.pth/top-1_class_prototypes/top-1_activated_prototype.png')\n","plt.figure(figsize=(3,3))\n","plt.imshow(img)\n","plt.show()\n","img = mpimg.imread('/content/dataset/cdsv5/test/1/pretrained/240_12push0.8884.pth/top-1_class_prototypes/top-2_activated_prototype.png')\n","plt.figure(figsize=(3,3))\n","plt.imshow(img)\n","plt.show()\n","img = mpimg.imread('/content/dataset/cdsv5/test/1/pretrained/240_12push0.8884.pth/top-1_class_prototypes/top-17_activated_prototype.png')\n","plt.figure(figsize=(3,3))\n","plt.imshow(img)\n","plt.show()"],"execution_count":null,"outputs":[]}]}